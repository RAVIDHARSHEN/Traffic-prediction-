{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LSTM,GRU,Dense, Dropout, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install these libraries \n",
    "pip install pydot\n",
    "pip install graphviz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1) \n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"c:\\\\Users\\\\Admin\\\\Downloads\\\\archive (1)\\\\train.csv\", encoding='utf-8')\n",
    "df2 = pd.read_csv(\"c:\\\\Users\\\\Admin\\\\Downloads\\\\archive (1)\\\\test.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1)).fit(df1['Flow (Veh/5 Minutes)'].values.reshape(-1, 1))\n",
    "train_data = scaler.transform(df1['Flow (Veh/5 Minutes)'].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "test_data = scaler.transform(df2['Flow (Veh/5 Minutes)'].values.reshape(-1, 1)).reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 12\n",
    "train, test = [], []\n",
    "for i in range(lag, len(train_data)):\n",
    "    train.append(train_data[i - lag: i + 1])\n",
    "for i in range(lag, len(test_data)):\n",
    "    test.append(test_data[i - lag: i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "# shuffle data (stateles case)\n",
    "np.random.shuffle(train)\n",
    "x_train = train[:, :-1]\n",
    "y_train = train[:, -1]\n",
    "x_test = test[:, :-1]\n",
    "y_test = test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df2.loc[df2['5 Minutes'] ==\"11/3/2020 15:00\"]\n",
    "a= x[\"Flow (Veh/5 Minutes)\"].index\n",
    "print(a.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_LSTM():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64,input_shape=(lag, 1),return_sequences=True))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_GRU():\n",
    "    model = Sequential()\n",
    "    model.add(GRU(64, input_shape=(lag, 1), return_sequences=True))\n",
    "    model.add(GRU(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_struct = \"GRU\"\n",
    "model_struct = \"LSTM\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_struct == \"LSTM\" :\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    model = build_LSTM()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mape'])\n",
    "    #monitor = EarlyStopping(monitor='val_loss', patience=40, verbose=1, mode='auto',restore_best_weights=True)\n",
    "    hist = model.fit(x_train, y_train,batch_size=64,epochs=200,validation_split=0.05)\n",
    "    model.save('models/LSTM.h5')\n",
    "    df = pd.DataFrame.from_dict(hist.history)\n",
    "    df.to_csv('models/LSTM_loss.csv', encoding='utf-8', index=False)        \n",
    "elif model_struct == \"GRU\" :        \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    model = build_GRU()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mape'])\n",
    "    #monitor = EarlyStopping(monitor='val_loss', patience=40, verbose=1, mode='auto',restore_best_weights=True)\n",
    "    hist = model.fit(x_train, y_train,batch_size=64,epochs=200,validation_split=0.05)\n",
    "    model.save('models/GRU.h5')\n",
    "    df = pd.DataFrame.from_dict(hist.history)\n",
    "    df.to_csv('models/GRU_loss.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(y_true, y_pred):\n",
    "    # the zero values we have in the dataset is a result to the sensors not reporting the data \n",
    "    # for that time for example server error or other types of errors we drop those values \n",
    "    # so they dont have false impact on the result \n",
    "    y_true = [x for x in y_true if x > 0]\n",
    "    y_pred = [y_pred[i] for i in range(len(y_true)) if y_true[i] > 0]\n",
    "      \n",
    "    # calculate the Mean Absolute Percentage Error \n",
    "    sums = 0 # initialize value\n",
    "    for i in range(len(y_pred)):\n",
    "        tmp = abs(y_true[i] - y_pred[i]) / y_true[i]\n",
    "        sums += tmp\n",
    "    mape = sums * (100 / len(y_pred))\n",
    "    # calculate variance score     \n",
    "    vs = metrics.explained_variance_score(y_true, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    print('explained_variance_score:%f' % vs)\n",
    "    print('mape:%f%%' % mape)\n",
    "    print('mae:%f' % mae)\n",
    "    print('mse:%f' % mse)\n",
    "    print('rmse:%f' % math.sqrt(mse))\n",
    "    print('r2:%f' % r2)\n",
    "    \n",
    "def plot_LSTM_oneDay(y_true, y_pred):\n",
    "    d = '2020-3-4 00:00'\n",
    "    x = pd.date_range(d, periods=288, freq='5min')\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(x, y_true, label='True Data')\n",
    "    for name, y_pred in zip(['LSTM'], y_preds):\n",
    "        ax.plot(x, y_pred[: 288], label=name)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Flow')\n",
    "    date_format = mpl.dates.DateFormatter(\"%H:%M\")\n",
    "    ax.xaxis.set_major_formatter(date_format)\n",
    "    fig.autofmt_xdate()\n",
    "    fig.savefig('./graphs/LSTM_oneDay.png')\n",
    "    plt.show()    \n",
    "def plot_GRU_oneDay(y_true, y_pred):\n",
    "    d = '2020-3-4 00:00'\n",
    "    x = pd.date_range(d, periods=288, freq='5min')\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(x, y_true, label='True Data')\n",
    "    for name, y_pred in zip(['GRU'], y_preds):\n",
    "        ax.plot(x, y_pred[: 288], label=name)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Flow')\n",
    "    date_format = mpl.dates.DateFormatter(\"%H:%M\")\n",
    "    ax.xaxis.set_major_formatter(date_format)\n",
    "    fig.autofmt_xdate()\n",
    "    fig.savefig('./graphs/GRU_oneDay.png')\n",
    "    plt.show()    \n",
    "def plot_models_oneDay(y_true, y_pred):\n",
    "    d = '2020-3-4 00:00'\n",
    "    x = pd.date_range(d, periods=288, freq='5min')\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(x, y_true, label='True Data')\n",
    "    for name, y_pred in zip(['LSTM', 'GRU'], y_preds):\n",
    "        ax.plot(x, y_pred[: 288], label=name)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Flow')\n",
    "    date_format = mpl.dates.DateFormatter(\"%H:%M\")\n",
    "    ax.xaxis.set_major_formatter(date_format)\n",
    "    fig.autofmt_xdate()\n",
    "    fig.savefig('./graphs/models_oneDay.png')\n",
    "    plt.show()\n",
    "def plot_models_oneWeek(y_true, y_pred):\n",
    "    x = pd.date_range(start ='2020-3-4 00:00',end ='2020-3-11 00:00', freq ='5min')  \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(x, y_true, label='True Data')\n",
    "    for name, y_pred in zip(['LSTM', 'GRU'], y_preds):\n",
    "        ax.plot(x, y_pred[: 2017], label=name)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Flow')\n",
    "    date_format = mpl.dates.DateFormatter(\"%H:%M\")\n",
    "    ax.xaxis.set_major_formatter(date_format)\n",
    "    fig.autofmt_xdate()\n",
    "    fig.savefig('./graphs/models_oneWeek.png')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = load_model('./models/LSTM.h5')\n",
    "gru = load_model(\"C:\\\\Users\\\\Admin\\\\Downloads\\\\GRU.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lstm, gru]\n",
    "names = ['LSTM', 'GRU']\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "y_preds = []\n",
    "for name, model in zip(names, models):\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "    file = './images/' + name + '.png'\n",
    "    plot_model(model, to_file=file, show_shapes=True)  \n",
    "    predicted = model.predict(x_test)\n",
    "    predicted = scaler.inverse_transform(predicted.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "    y_preds.append(predicted)\n",
    "    print(name)\n",
    "    evaluate_models(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_LSTM_oneDay(y_test[: 288],y_preds[: 288])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models_oneDay(y_test[: 288],y_preds[: 288]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models_oneWeek(y_test[: 2017],y_preds[: 2017])  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
